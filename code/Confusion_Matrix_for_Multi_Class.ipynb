{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$\\text{Confusion Matrix for Multi Class}$$\n",
    "\n",
    "$$\\text{Claudio  C.  Kandza-Tadi}$$\n",
    "\n",
    "\n",
    "$$\\text{African Master of Machine Intelligence (AMMI), AIMS Rwanda}$$\n",
    "\n",
    "$$ (March, 2020)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "A confusion matrix is a table that is often used to summarize the performance of a classification algorithm (or \"classifier\") on a set of test data whose true values are known. Confusion matrix were first discussed by Townsend [[1]](https://doi.org/10.3758/BF03213026), and it was in 1998 that the term confusion matrix became popular in Machine Learning thanks to Kohavi and Provost [[2]](http://robotics.stanford.edu/~ronnyk/glossary.html). In supervised machine learning, confusion matrix is a matrix that measures the quality of\n",
    "a classification system. Each row of the matrix corresponds to an actual class and each column corresponds to a predicted class. Classification accuracy alone can be misleading if you have an unequal number of observations in each\n",
    "class or if you have more than two classes in your data set. One of the advantages of the confusion matrix is that it quickly shows whether a classification system manages to classify correctly. The confusion\n",
    "matrix itself is relatively simple to understand, but the associated terminology and the calculation of certain elements of the matrix can be confusing, especially in the case of multiple classes. Manliguez  [[3]](https://www.researchgate.net/publication/310799885_Generalized_Confusion_Matrix_for_Multiple_Classes) derived the generalized formula to calculate the precision, the recall, the\n",
    "specificity and the global accuracy of the system having multiple classes. His results were used in eight (8) different works ([[4]](https://link.springer.com/chapter/10.1007/978-3-030-26428-4_7) , [[5]](https://ieeexplore.ieee.org/abstract/document/8938419), [[6]](https://ieeexplore.ieee.org/document/8834531), [[7]](https://doi.org/10.1007/s10772-018-9527-4), [[8]](https://www.semanticscholar.org/paper/A-Novel-Intelligent-System-for-Diagnosing-some-of-Elalfi-Elalmi/02d4c1119e9ee00ec657f591c6a59e33786e1a43), [[9]](https://iopscience.iop.org/article/10.1088/1742-6596/1417/1/012015), [[10]](https://www.mdpi.com/1424-8220/20/1/55), [[11]](https://www.atlantis-press.com/journals/ijcis/125934171/view)) to compute the overall accuracy in most cases, but we have realized that it were the only well defined generalized classification metric in Manliguez [[3]](https://www.researchgate.net/publication/310799885_Generalized_Confusion_Matrix_for_Multiple_Classes). The aim of this document is to show the evidence of the mistakes in some generalized classification metrics and also to correct them. To achieve that objective, we have used the analytical approach for binary classification case and the computational approach using python package scikit-learn for the ternary Classification case study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Form for Multiple Classes\n",
    "\n",
    "Given that there are $n$ classes, Table 1 shows the format of a confusion matrix for multiple classes.\n",
    "<img src=\"Confusion Matrix.png\" width=\"400\" height=\"200\">\n",
    "\n",
    "Source : [[3]](https://www.researchgate.net/publication/310799885_Generalized_Confusion_Matrix_for_Multiple_Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Confusion Matrix for Multiple Classes\n",
    "\n",
    "### Generalized formula for the number of true/false positive, true/false negative\n",
    "\n",
    "- The total numbers of false negative (TFN) for each class i is given by:\n",
    "\n",
    "$$TFN_i = \\sum\\limits_{\\substack{j=1 \\\\ j\\neq i}}^n  x_{ij}$$\n",
    "\n",
    "- The total numbers of false positive (TFP) for each class i is given by:\n",
    "\n",
    "$$TFP_i = \\sum\\limits_{\\substack{j=1 \\\\ j\\neq i}}^n  x_{ji}$$\n",
    "\n",
    "- The total numbers of true negative (TTN) for each class i is given by:\n",
    "\n",
    "$$TTN_i = \\sum\\limits_{\\substack{j=1 \\\\ j\\neq i}}^n \\sum\\limits_{\\substack{k=1 \\\\ k\\neq i}}^n x_{jk}$$\n",
    "\n",
    "- The total numbers of true negative in the system (TTN) is given by:\n",
    "\n",
    "$$TTN_{all} = \\sum_{j=1}^n  TTN_i$$\n",
    "\n",
    "- The total numbers of true positive in the system (TTP) is given by:\n",
    "\n",
    "$$TTP_{all} = \\sum_{j=1}^n  x_{jj}.$$\n",
    "\n",
    "### Generalized Classification Metrics\n",
    "\n",
    "In this section, we are going to present the results for the analytical and computational aprroaches. For the analytical part we have considered the binary classification case and the table below shows the format of confusion matrix for two (2) classes.\n",
    "\n",
    "**The following table shows the format of a confusion matrix for two(2) classes**\n",
    "<img src=\"Binary case.png\" width=\"400\" height=\"200\">\n",
    "\n",
    "\n",
    "   - True positive (TP): correctly classified or detected.\n",
    "   - False positive (FP): incorrectly classified or detected. It represents the type I error.\n",
    "   - False negative (FN): incorrectly rejected. It represents the type II error.\n",
    "   - True negative (TN): correctly rejected.\n",
    "\n",
    "#### Precision\n",
    "\n",
    "- The generalized precision (P)for each class $i$\n",
    "\n",
    "Precision  also called sensitivity helps us to measures the proportion of actual positives that are correctly identified. And it has been defined such as\n",
    "\n",
    "$$P_i = \\frac{TTP_{all}}{TTP_{all} + TFP_i}$$\n",
    "\n",
    "This equation does take into account the binary classification. It is even not working for three classes. below we are going to show it analytically for a binary classification problem.\n",
    "\n",
    "We know that precision for binary classification is given by\n",
    "\n",
    "$$Precision = \\frac{TP}{TP + FP}.$$\n",
    "\n",
    "Now, considering the generalized formala for precision, we have\n",
    "\n",
    "$$Precision_1 = \\frac{\\sum_{j=1}^2  x_{jj}}{\\sum_{j=1}^2  x_{jj} + \\sum\\limits_{\\substack{j=2 \\\\ j\\neq 1}}^2  x_{j1}}.$$\n",
    "\n",
    "And taking into account the elements of the table above, we get:\n",
    "$$\\sum_{j=1}^2  x_{jj}=x_{11} + x_{22} = TP + TN,$$\n",
    "$$\\sum\\limits_{\\substack{j=2 \\\\ j\\neq 1}}^2  x_{j1} = x_{21} = FP.$$\n",
    "\n",
    "Then,\n",
    "$$Precision_1 = \\frac{TP + TN}{TP + TN + FP}.$$\n",
    "\n",
    "It is clear that,\n",
    "\n",
    "$$\\frac{TP + TN}{TP + TN + FP} \\neq  \\frac{TP}{TP + FP}.$$\n",
    "\n",
    "Therefore, the generalized precision formala does not work for binary classification.\n",
    "\n",
    "\n",
    "#### Recall\n",
    "\n",
    "- The generalized recall (R)for each class $i$\n",
    "\n",
    "Recall helps us to answer the following question: what proportion of actual Positives is correctly classified? And it have been defined such as\n",
    "$$R_i = \\frac{TTP_{all}}{TTP_{all} + TFN_i}$$\n",
    "\n",
    "In the case of binary classification problem, the generalized recall is given by\n",
    "\n",
    "$$R_1 = \\frac{\\sum_{j=1}^2  x_{jj}}{\\sum_{j=1}^2  x_{jj} + \\sum\\limits_{\\substack{j=2 \\\\ j\\neq i}}^2  x_{1j}} = \\frac{x_{11}+x_{22}}{x_{11}+x_{22} + x_{12}}$$\n",
    "\n",
    "Then, \n",
    "$$R_1 = \\frac{TP + TN}{TP+TN + FN} \\neq \\frac{TP}{TP + FN}  $$\n",
    "with $\\frac{TP}{TP + FN}$ the known formula for recall in the case of two classes.\n",
    "\n",
    "We can see, the generalized recall is not working for binary classification problem.\n",
    "\n",
    "#### Specificity\n",
    "\n",
    "- The generalized specificity(S) for each class $i$\n",
    "\n",
    "Specificity, also called the true negative rate helps us to measures the proportion of actual negatives that are correctly identified. And have been defined such as\n",
    "\n",
    "$$S_i = \\frac{TTN_{all}}{TTN_{all} + TFP_i}.$$\n",
    "\n",
    "Unfortunately, the document did not provide the generalized formular for Total number of True Negative $TTN_{all}$.\n",
    "\n",
    "#### Overall Accuracy\n",
    "\n",
    "- The Overall accuracy\n",
    "\n",
    "Accuracy helps us to measure  the proportion of correctly predicted observation to the total observations. And the overall accuracy it has been defined as\n",
    "\n",
    "$$\\text{Overall Accuracy} = \\frac{TTP_{all}}{\\text{Total  Number of Testing Entries}}.$$\n",
    "\n",
    "$$\\text{Overall Accuracy} = \\frac{\\sum_{j=1}^n  x_{jj}}{\\sum_{i=1}^n \\sum_{j=1}^n x_{ij}}.$$\n",
    "\n",
    "For the above binary classification problem we have,\n",
    "\n",
    "$$\\text{Overall Accuracy} = \\frac{\\sum_{j=1}^2  x_{jj}}{\\sum_{i=1}^2 \\sum_{j=1}^2 x_{ij}} = \\frac{x_{11}+x_{22}}{x_{11}+x_{12}+x_{21}+x_{22}}.$$\n",
    "\n",
    "It follows that,\n",
    "$$\\text{Overall Accuracy} = \\frac{TP + TN}{TP+FN+FP+TN}.$$\n",
    "Clearly, the generalized overall accuracy have been well defined  by the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1 1]\n",
      " [6 2 2]\n",
      " [3 0 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "# Constants\n",
    "C=\"Cat\"\n",
    "F=\"Fish\"\n",
    "H=\"Hen\"\n",
    "\n",
    "# True values\n",
    "y_true = [C,C,C,C,C,C, F,F,F,F,F,F,F,F,F,F, H,H,H,H,H,H,H,H,H]\n",
    "# Predicted values\n",
    "y_pred = [C,C,C,C,H,F, C,C,C,C,C,C,H,H,F,F, C,C,C,H,H,H,H,H,H]\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source : [Boaz Shmueli,Towards Data Science A Medium. Cat-Fish-Hen ternary classification example](https://towardsdatascience.com/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python function for the generalized total number of true/false positive, true/false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The total numbers of false negative (TFN) for each class i\n",
    "def TFN(A, i):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number for each class\n",
    "       rows : represent the actual number for each class\"\"\"\n",
    "    n = A.shape[0]\n",
    "    sum_ = 0\n",
    "    for j in range(n):\n",
    "        if i != j:\n",
    "            sum_ += A[i,j]\n",
    "    return sum_\n",
    "\n",
    "\n",
    "#The total numbers of false positive (TFP) for each class i \n",
    "def TFP(A, i):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\"\"\"\n",
    "    n = A.shape[0]\n",
    "    sum_ = 0\n",
    "    for j in range(n):\n",
    "        if i != j:\n",
    "            sum_ += A[j,i]\n",
    "    return sum_\n",
    "\n",
    "\n",
    "#The total numbers of true negative (TTN) for each class i\n",
    "def TTN(A,i):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\"\"\"\n",
    "    n = A.shape[0]\n",
    "    sum_ = 0\n",
    "    for j in range(n):\n",
    "            for k in range(n):\n",
    "                if (j != i) and (k != i):\n",
    "                    sum_ += A[j,k]\n",
    "    return sum_\n",
    "\n",
    "#The total numbers of true positive in the system (TTP)\n",
    "def TTP_all(A):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\"\"\"\n",
    "    return np.trace(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python function for the generalized classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The generalized precision (P)for each class i\n",
    "def Precision_G(A,i):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\"\"\"\n",
    "    return TTP_all(A)/(TTP_all(A)+TFP(A,i))\n",
    "\n",
    "#The generalized recall (R)for each class i\n",
    "def Recall_G(A,i):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\"\"\"\n",
    "    return TTP_all(A)/(TTP_all(A)+TFN(A,i))\n",
    "\n",
    "#The generalized specificity(S) for each class i\n",
    "def Specificity_G(A,i):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\"\"\"\n",
    "    return TTN_all(A)/(TTN_all(A)+TFP(A,i))\n",
    "\n",
    "#The Overall accuracy\n",
    "def OverallAccuracy(A):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\"\"\"\n",
    "    n = A.shape[0]\n",
    "    sum_ = 0\n",
    "    for j in range(n):\n",
    "            for k in range(n):\n",
    "                sum_ += A[j,k]\n",
    "    return TTP_all(A)/sum_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confusion matrix for Cat, Fish and Hen ternary classification\n",
    "Confusion_matrix = metrics.confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the results\n",
    "def display_G(A,label):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\"\"\"\n",
    "    dic = {'Precision':[Precision_G(A,i) for i in range(A.shape[0])],\n",
    "           'Recall':[Recall_G(A,i) for i in range(A.shape[0])]}\n",
    "    result = pd.DataFrame(dic, index=label)\n",
    "    return result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison between Scikit-learn and Generalized confusion matrix for multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Cat      0.308     0.667     0.421         6\n",
      "        Fish      0.667     0.200     0.308        10\n",
      "         Hen      0.667     0.667     0.667         9\n",
      "\n",
      "   micro avg      0.480     0.480     0.480        25\n",
      "   macro avg      0.547     0.511     0.465        25\n",
      "weighted avg      0.581     0.480     0.464        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the precision and recall, among other metrics using Scikit-learn\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cat</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fish</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hen</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Precision    Recall\n",
       "Cat    0.571429  0.857143\n",
       "Fish   0.923077  0.600000\n",
       "Hen    0.800000  0.800000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = ['Cat','Fish','Hen']\n",
    "display_G(Confusion_matrix,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has been observed that even for ternary classification problem, the generalized classification metrics are not well defined. In the following line, we are going to correct that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrected Generalized Confusion Matrix for Multiple Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrected Classification Metrics for Mutiple Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The corrected generalized precision (P)for each class $i$ is given by\n",
    "\n",
    "$$P_i = \\frac{TP_{i}}{TP_{i} + FP_i}$$\n",
    "where $TP_i = x_{ii}$ and $FP_i = \\sum\\limits_{\\substack{j=1 \\\\ j\\neq i}}^n  x_{ji}$\n",
    "\n",
    "\n",
    "- The corrected generalized recall (R)for each class $i$ is given by\n",
    "\n",
    "$$R_i = \\frac{TP_i}{TP_i + FN_i}$$\n",
    "where $TP_i = x_{ii}$ and $FN_i = \\sum\\limits_{\\substack{j=1 \\\\ j\\neq i}}^n  x_{ij}$\n",
    "\n",
    "\n",
    "- The corrected generalized Specificity (Sp)for each class $i$ is given by\n",
    "\n",
    "$$Sp_i = \\frac{TN_i}{TN_i + FP_i}$$\n",
    "\n",
    "where $TN_i = \\sum\\limits_{\\substack{j=1 \\\\ j\\neq i}}^n \\sum\\limits_{\\substack{k=1 \\\\ k\\neq i}}^n x_{jk}$\n",
    "\n",
    "- The generalized Accuracy (Accur) for each class $i$ is given by\n",
    "\n",
    "$$Accur_i = \\frac{TP_i + TN_i}{TP_i + TN_i + FP_i + FN_i}$$\n",
    "where $TP_i = x_{ii}$\n",
    "\n",
    "- The Overall Accuracy of the system is given by\n",
    "\n",
    "$$\\text{Overall Accuracy} = \\frac{TTP_{all}}{TTE}$$\n",
    "\n",
    "where $TTE = \\sum_{i=1}^n \\sum_{j=1}^n  x_{ij}$ (total numbers of testing entries in the system) and $TTP_{all} = \\sum_{j=1}^n  x_{jj}$.\n",
    "\n",
    "**NB: TTN = TN, TFP = FP and TFN = FN, they are well defined.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python function for the corrected generalized classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The corrected generalized precision (P) function for each class i\n",
    "def Precision_CG(A,i):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\n",
    "       \"\"\"\n",
    "    return A[i,i]/(A[i,i]+TFP(A,i))\n",
    "\n",
    "#The corrected generalized recall (R) function for each class i\n",
    "def Recall_CG(A,i):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\"\"\"\n",
    "    return A[i,i]/(A[i,i]+TFN(A,i))\n",
    "\n",
    "#The corrected generalized Specificity (Sp) function for each class i\n",
    "def Specificity_CG(A,i):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\"\"\"\n",
    "    return TTN(A,i)/(TTN(A,i)+TFP(A,i))\n",
    "\n",
    "#The generalized Accuracy (Accur)for each class i\n",
    "\"\"\"\"NOT SURE ABOUT IT\"\"\"\n",
    "def Accuracy_CG(A,i):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\"\"\"\n",
    "    return (A[i,i] + TTN(A,i))/(A[i,i] + TTN(A,i)+TFP(A,i)+TFN(A,i))\n",
    "\n",
    "# Precision of the all system is equal to the Overall Accuracy\n",
    "def Accuracy_Sys(A):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\"\"\"\n",
    "    return np.trace(A)/np.sum(A)\n",
    "\n",
    "# F1 Score(Harmonic mean of precision and recall)\n",
    "def F1_Score(A,i,b):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\n",
    "       b : commonly 0.5, 1, 2\"\"\"\n",
    "    N_ = (1+b)*Precision_CG(A,i)*Recall_CG(A,i)\n",
    "    D_ = (b**2)*Precision_CG(A,i)+Recall_CG(A,i)\n",
    "    return N_ /D_\n",
    "\n",
    "\n",
    "# Macro Average of the Precision, Recall, F1_Score\n",
    "def Macro_Average(A):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\n",
    "       b : commonly 0.5, 1, 2\"\"\"\n",
    "    Nb_Class = A.shape[0]\n",
    "    sum_P = 0\n",
    "    sum_R = 0\n",
    "    sum_F1S = 0\n",
    "    for i in range(Nb_Class):\n",
    "        sum_P += Precision_CG(A,i)\n",
    "        sum_R += Recall_CG(A,i)\n",
    "        sum_F1S += F1_Score(A,i,1)\n",
    "    sum_ = np.array([sum_P,sum_R,sum_F1S])\n",
    "    return sum_/Nb_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_CG(A,labels):\n",
    "    \"\"\"A : confusion matrix (square matrix)\n",
    "       columns: represent the predicted number\n",
    "       rows : represent the actual number\"\"\"\n",
    "    P = [Precision_CG(A,i) for i in range(A.shape[0])]\n",
    "    R = [Recall_CG(A,i) for i in range(A.shape[0])]\n",
    "    Sp = [Specificity_CG(A,i) for i in range(A.shape[0])]\n",
    "    F1 = [F1_Score(A,i,1) for i in range(A.shape[0])]\n",
    "    Accur = [Accuracy_CG(A,i) for i in range(A.shape[0])]\n",
    "    dic = {'Precision':P,\n",
    "           'Recall':R,\n",
    "          'Specificity':Sp,\n",
    "           'F1 Score':F1,\n",
    "          'Accuracy':Accur,\n",
    "          'Global Accuracy':[Accuracy_Sys(A)]+['_' for i in range(A.shape[0]-1)]}\n",
    "    result = pd.DataFrame(dic, index=labels)\n",
    "    return result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison between Scikit-learn and Corrected generalized confusion matrix for multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Cat      0.308     0.667     0.421         6\n",
      "        Fish      0.667     0.200     0.308        10\n",
      "         Hen      0.667     0.667     0.667         9\n",
      "\n",
      "   micro avg      0.480     0.480     0.480        25\n",
      "   macro avg      0.547     0.511     0.465        25\n",
      "weighted avg      0.581     0.480     0.464        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the precision and recall, among other metrics using Scikit-learn\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Global Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cat</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fish</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.64</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hen</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.76</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Precision    Recall  Specificity  F1 Score  Accuracy Global Accuracy\n",
       "Cat    0.307692  0.666667     0.526316  0.421053      0.56            0.48\n",
       "Fish   0.666667  0.200000     0.933333  0.307692      0.64               _\n",
       "Hen    0.666667  0.666667     0.812500  0.666667      0.76               _"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = ['Cat','Fish','Hen']\n",
    "display_CG(Confusion_matrix,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has been observed that the corrected generalized classification metrics for multi classes is given the same results by using Scikit-learn function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Considering the importance of the confusion matrix in the fields of machine learning, we felt that it was useful point out the mistakes on the classification metrics  and then correct them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "1. Townsend, J. T. (1971). Theoretical analysis of an alphabetic confusion matrix. Perception & Psychophysics, 9(1), 40-50.  https://doi.org/10.3758/BF03213026\n",
    "\n",
    "2. Ron, K., & Foster, P. (1998). Special issue on applications of machine learning and the knowledge discovery process. Journal of Machine Learning, 30, 271-274.\n",
    "\n",
    "3. Manliguez, C. (2016). Generalized confusion matrix for multiple classes.\n",
    "\n",
    "4. Abiyoga, A. W., & Iswari, N. M. S. (2019). Decision Support System for Choosing an Elective Course Using Naive Bayes Classifier. Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing, 850, 97.\n",
    "\n",
    "5. Pratama, B. T., Utami, E., & Sunyoto, A. (2019). The Impact of Using Domain Specific Features on Lexicon Based Sentiment Analysis on Indonesian App Review. In 2019 International Conference on Information and Communications Technology (ICOIACT) (pp. 474-479). IEEE.\n",
    "    \n",
    "6. Pratama, B. T., Utami, E., & Sunyoto, A. (2019). A Comparison of the Use of Several Different Resources on Lexicon Based Indonesian Sentiment Analysis on App Review Dataset. In 2019 International Conference of Artificial Intelligence and Information Technology (ICAIIT) (pp. 282-287). IEEE.\n",
    "    \n",
    "7. Sardar, V. M., & Shirbahadurkar, S. D. (2018). Speaker identification of whispering speech: an investigation on selected timbrel features and KNN distance measures. International Journal of Speech Technology, 21(3), 545-553. https://doi.org/10.1007/s10772-018-9527-4\n",
    "    \n",
    "8. Elalfi, A.E., Elalmi, M.E., & Zahran, F.A. (2019). A Novel Intelligent System for Diagnosing some of Humans' Respiratory System Diseases.International Journal of Computer Applications 181(41):19-29.\n",
    "    \n",
    "9. Kharis, S. A. A., Hadi, I., & Hasanah, K. A. (2019). Multiclass Classification of Brain Cancer with Multiple Multiclass Artificial Bee Colony Feature Selection and Support Vector Machine. In Journal of Physics: Conference Series (Vol. 1417, No. 1, p. 012015). IOP Publishing.\n",
    "    \n",
    "10. Dalarmelina, N. D. V., Teixeira, M. A., & Meneguette, R. I. (2020). A Real-Time Automatic Plate Recognition System Based on Optical Character Recognition and Wireless Sensor Networks for ITS. Sensors, 20(1), 55.\n",
    "    \n",
    "11. Grifoni, P., Caschera, M. C., & Ferri, F. (2020). DAMA: A Dynamic Classification of Multimodal Ambiguities. International Journal of Computational Intelligence Systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
